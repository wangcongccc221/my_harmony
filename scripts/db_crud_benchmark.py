#!/usr/bin/env python3
"""
å¤šç”¨æˆ· CRUD å‹æµ‹è„šæœ¬
 - å¹¶å‘æ¨¡æ‹Ÿå¤šäººåŒæ—¶è®¿é—® HTTP + æ•°æ®åº“æ¥å£
 - åˆ†åˆ«ç»Ÿè®¡ Query / Insert / Update / Delete çš„è€—æ—¶åˆ†å¸ƒ
 - æ”¯æŒè‡ªå®šä¹‰æ“ä½œå æ¯”ä¸æ€»æ“ä½œæ•°
"""

import argparse
import json
import random
import statistics
import threading
import time
from collections import defaultdict
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple

import requests


@dataclass
class OperationMetrics:
    """è®°å½•å•ä¸ªæ“ä½œç±»å‹çš„ç»Ÿè®¡æ•°æ®"""
    name: str
    latencies: List[float] = field(default_factory=list)
    success: int = 0
    failed: int = 0
    lock: threading.Lock = field(default_factory=threading.Lock, repr=False)

    def record(self, success: bool, latency_ms: float):
        with self.lock:
            if success:
                self.success += 1
                self.latencies.append(latency_ms)
            else:
                self.failed += 1

    def summarize(self) -> Dict:
        with self.lock:
            total = self.success + self.failed
            if self.success == 0:
                return {
                    "operation": self.name,
                    "total": total,
                    "success": self.success,
                    "failed": self.failed,
                    "success_rate": "0%",
                    "latency": {}
                }

            def percentile(values: List[float], percent: float) -> float:
                if not values:
                    return 0.0
                k = (len(values) - 1) * percent / 100
                f = int(k)
                c = min(f + 1, len(values) - 1)
                if f == c:
                    return values[f]
                return values[f] + (values[c] - values[f]) * (k - f)

            lat_sorted = sorted(self.latencies)
            summary = {
                "operation": self.name,
                "total": total,
                "success": self.success,
                "failed": self.failed,
                "success_rate": f"{self.success * 100 / total:.2f}%",
                "latency": {
                    "min_ms": round(lat_sorted[0], 2),
                    "max_ms": round(lat_sorted[-1], 2),
                    "avg_ms": round(statistics.mean(lat_sorted), 2),
                    "median_ms": round(statistics.median(lat_sorted), 2),
                    "p90_ms": round(percentile(lat_sorted, 90), 2),
                    "p95_ms": round(percentile(lat_sorted, 95), 2),
                    "p99_ms": round(percentile(lat_sorted, 99), 2),
                    "std_ms": round(statistics.stdev(lat_sorted), 2) if len(lat_sorted) > 1 else 0.0
                }
            }
            return summary


class SharedIdPool:
    """ä¿å­˜å·²æ’å…¥æˆåŠŸçš„è®°å½• IDï¼Œä¾› Update/Delete ä½¿ç”¨"""

    def __init__(self):
        self.ids: List[int] = []
        self.lock = threading.Lock()

    def add(self, record_id: int):
        with self.lock:
            self.ids.append(record_id)

    def get_random(self) -> Optional[int]:
        with self.lock:
            if not self.ids:
                return None
            return random.choice(self.ids)

    def remove(self, record_id: int):
        with self.lock:
            if record_id in self.ids:
                self.ids.remove(record_id)


class CrudBenchmark:
    def __init__(self, base_url: str, workers: int, ops_per_worker: int,
                 mix: Dict[str, int], warmup_inserts: int = 20):
        self.base_url = base_url.rstrip("/")
        self.workers = workers
        self.ops_per_worker = ops_per_worker
        self.mix = mix
        self.warmup_inserts = warmup_inserts

        self.metrics: Dict[str, OperationMetrics] = {
            "query": OperationMetrics("query"),
            "insert": OperationMetrics("insert"),
            "update": OperationMetrics("update"),
            "delete": OperationMetrics("delete"),
        }
        self.id_pool = SharedIdPool()
        self.total_lock = threading.Lock()
        self.total_ops = 0
        self.start_time = 0.0
        self.end_time = 0.0

    def run(self):
        print("ğŸš€ å¯åŠ¨ CRUD å‹æµ‹")
        print(f"æœåŠ¡å™¨: {self.base_url}")
        print(f"å¹¶å‘ç”¨æˆ·: {self.workers}")
        print(f"æ¯ä¸ªç”¨æˆ·æ“ä½œæ•°: {self.ops_per_worker}")
        print(f"æ“ä½œå æ¯”: {self.mix}")
        print(f"é¢„çƒ­æ’å…¥: {self.warmup_inserts} æ¡\n")

        self._warmup_data()

        self.start_time = time.time()
        threads = []
        for i in range(self.workers):
            th = threading.Thread(target=self._worker, args=(i,), daemon=True)
            threads.append(th)
            th.start()

        for th in threads:
            th.join()
        self.end_time = time.time()

        self._print_report()

    def _warmup_data(self):
        if self.warmup_inserts <= 0:
            return
        print("âš™ï¸ é¢„çƒ­é˜¶æ®µï¼šæ’å…¥åŸºç¡€æ•°æ®")
        for _ in range(self.warmup_inserts):
            success, _, new_id = self._insert_record(requests.Session())
            if success and new_id:
                self.id_pool.add(new_id)
        print(f"âœ… é¢„çƒ­å®Œæˆï¼ŒID æ± å¤§å°: {len(self.id_pool.ids)}\n")

    def _worker(self, worker_id: int):
        session = requests.Session()
        rng = random.Random(time.time() + worker_id)
        choices = self._build_choice_table()

        for _ in range(self.ops_per_worker):
            op = self._pick_operation(rng, choices)
            if op == "query":
                success, latency = self._query_list(session, rng)
                self.metrics["query"].record(success, latency)
            elif op == "insert":
                success, latency, record_id = self._insert_record(session)
                if success and record_id:
                    self.id_pool.add(record_id)
                self.metrics["insert"].record(success, latency)
            elif op == "update":
                success, latency = self._update_record(session, rng)
                self.metrics["update"].record(success, latency)
            elif op == "delete":
                success, latency = self._delete_record(session, rng)
                self.metrics["delete"].record(success, latency)
            with self.total_lock:
                self.total_ops += 1

    def _build_choice_table(self) -> List[Tuple[str, int]]:
        total = sum(self.mix.values())
        choices = []
        cumulative = 0
        for op, weight in self.mix.items():
            cumulative += weight
            choices.append((op, cumulative))
        return choices

    def _pick_operation(self, rng: random.Random, choices: List[Tuple[str, int]]) -> str:
        total_weight = choices[-1][1]
        roll = rng.randint(1, total_weight)
        for op, threshold in choices:
            if roll <= threshold:
                return op
        return choices[-1][0]

    def _query_list(self, session: requests.Session, rng: random.Random) -> Tuple[bool, float]:
        params = {"page": rng.randint(1, 5), "size": 20}
        url = f"{self.base_url}/api/processing"
        start = time.time()
        try:
            resp = session.get(url, params=params, timeout=10)
            latency = (time.time() - start) * 1000
            ok = resp.status_code == 200
            return ok, latency
        except requests.RequestException:
            return False, (time.time() - start) * 1000

    def _insert_record(self, session: requests.Session) -> Tuple[bool, float, Optional[int]]:
        payload = {
            "customerName": f"å‹æµ‹ç”¨æˆ·-{random.randint(1000, 9999)}",
            "farmName": f"å†œåœº-{random.randint(1, 100)}",
            "fruitName": random.choice(["è‹¹æœ", "æ¢¨", "æ©™å­", "æ¡ƒå­"]),
            "status": random.choice(["è¿›è¡Œä¸­", "å·²å®Œæˆ"]),
            "startTime": "2025-01-15 10:00:00",
            "endTime": "2025-01-15 11:00:00",
            "weight": round(random.uniform(50, 150), 2),
            "count": random.randint(100, 3000)
        }
        url = f"{self.base_url}/api/processing"
        headers = {"Content-Type": "application/json"}
        start = time.time()
        try:
            resp = session.post(url, json=payload, headers=headers, timeout=10)
            latency = (time.time() - start) * 1000
            if resp.status_code in (200, 201):
                try:
                    data = resp.json()
                    new_id = None
                    if isinstance(data, dict):
                        # å¸¸è§„å“åº”: {"ok": true, "data": {"id": 1}}
                        payload = data.get("data")
                        if isinstance(payload, dict):
                            new_id = payload.get("id")
                        elif isinstance(payload, list) and payload:
                            first = payload[0]
                            if isinstance(first, dict):
                                new_id = first.get("id")
                    elif isinstance(data, list) and data:
                        first = data[0]
                        if isinstance(first, dict):
                            new_id = first.get("id")
                except (json.JSONDecodeError, AttributeError):
                    new_id = None
                return True, latency, new_id
            return False, latency, None
        except requests.RequestException:
            return False, (time.time() - start) * 1000, None

    def _update_record(self, session: requests.Session, rng: random.Random) -> Tuple[bool, float]:
        record_id = self.id_pool.get_random()
        if record_id is None:
            # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œé€€åŒ–ä¸ºæŸ¥è¯¢ï¼Œé¿å…æ— æ•ˆè¯·æ±‚
            return self._query_list(session, rng)
        payload = {
            "status": random.choice(["è¿›è¡Œä¸­", "å·²å®Œæˆ"]),
            "weight": round(random.uniform(60, 200), 2)
        }
        url = f"{self.base_url}/api/processing/{record_id}"
        headers = {"Content-Type": "application/json"}
        start = time.time()
        try:
            resp = session.put(url, json=payload, headers=headers, timeout=10)
            latency = (time.time() - start) * 1000
            return resp.status_code == 200, latency
        except requests.RequestException:
            return False, (time.time() - start) * 1000

    def _delete_record(self, session: requests.Session, rng: random.Random) -> Tuple[bool, float]:
        record_id = self.id_pool.get_random()
        if record_id is None:
            return self._query_list(session, rng)
        url = f"{self.base_url}/api/processing/{record_id}"
        start = time.time()
        try:
            resp = session.delete(url, timeout=10)
            latency = (time.time() - start) * 1000
            success = resp.status_code == 200
            if success:
                self.id_pool.remove(record_id)
            return success, latency
        except requests.RequestException:
            return False, (time.time() - start) * 1000

    def _print_report(self):
        duration = self.end_time - self.start_time
        overall_qps = self.total_ops / duration if duration > 0 else 0

        print("\n" + "=" * 70)
        print("ğŸ“Š å‹æµ‹æ€»è§ˆ")
        print("=" * 70)
        print(f"æ€»æ“ä½œæ•°: {self.total_ops}")
        print(f"æ€»è€—æ—¶:   {duration:.2f} ç§’")
        print(f"æ•´ä½“ QPS: {overall_qps:.2f} ops/s")

        print("\nğŸ” å„æ“ä½œç±»å‹ç»Ÿè®¡ï¼š")
        for op in ["query", "insert", "update", "delete"]:
            summary = self.metrics[op].summarize()
            print(f"\n[{op.upper()}]")
            print(f"  æ€»æ•°       : {summary['total']}")
            print(f"  æˆåŠŸ/å¤±è´¥  : {summary['success']} / {summary['failed']}")
            print(f"  æˆåŠŸç‡     : {summary['success_rate']}")
            if summary["latency"]:
                lat = summary["latency"]
                print(f"  å»¶è¿Ÿ(ms)   : min {lat['min_ms']} | avg {lat['avg_ms']} | median {lat['median_ms']}")
                print(f"               p90 {lat['p90_ms']} | p95 {lat['p95_ms']} | p99 {lat['p99_ms']}")
                print(f"               max {lat['max_ms']} | std {lat['std_ms']}")

        print("\nâœ… å‹æµ‹å®Œæˆï¼")


def parse_mix(mix_str: str) -> Dict[str, int]:
    allowed = {"query", "insert", "update", "delete"}
    mix = {}
    for part in mix_str.split(","):
        if "=" not in part:
            continue
        op, value = part.split("=", 1)
        op = op.strip().lower()
        if op not in allowed:
            raise ValueError(f"æœªçŸ¥æ“ä½œ: {op}")
        mix[op] = int(value)
    if not mix:
        raise ValueError("æ“ä½œå æ¯”ä¸èƒ½ä¸ºç©º")
    # ç¡®ä¿æ‰€æœ‰æ“ä½œéƒ½æœ‰å æ¯”ï¼ˆæœªæä¾›åˆ™é»˜è®¤ 0ï¼‰
    for op in allowed:
        mix.setdefault(op, 0)
    return mix


def main():
    parser = argparse.ArgumentParser(description="å¤šç”¨æˆ· CRUD å‹æµ‹è„šæœ¬")
    parser.add_argument("--url", default="http://localhost:8080", help="æœåŠ¡å™¨åœ°å€")
    parser.add_argument("--workers", type=int, default=20, help="å¹¶å‘ç”¨æˆ·æ•°")
    parser.add_argument("--ops-per-worker", type=int, default=50, help="æ¯ä¸ªç”¨æˆ·çš„æ“ä½œæ¬¡æ•°")
    parser.add_argument("--mix", default="query=50,insert=20,update=15,delete=15",
                        help="æ“ä½œå æ¯”ï¼Œæ ¼å¼: query=50,insert=20,update=15,delete=15")
    parser.add_argument("--warmup", type=int, default=20, help="å‹æµ‹å‰é¢„çƒ­æ’å…¥æ•°é‡")

    args = parser.parse_args()
    mix = parse_mix(args.mix)

    benchmark = CrudBenchmark(
        base_url=args.url,
        workers=args.workers,
        ops_per_worker=args.ops_per_worker,
        mix=mix,
        warmup_inserts=args.warmup
    )
    benchmark.run()


if __name__ == "__main__":
    main()

